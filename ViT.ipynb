{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\CodeProject\\nn_work\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTFeatureExtractor, BertTokenizer\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "dataset='deepfashion-multimodal'\n",
    "img_path = f'data/{dataset}/images'\n",
    "train_json_path= f'data/{dataset}/train_captions.json'\n",
    "test_json_path= f'data/{dataset}/test_captions.json'\n",
    "vocab_path = f'data/{dataset}/vocab.json'\n",
    "\n",
    "def idx_to_word(idx, vocab):\n",
    "    reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "    return reverse_vocab.get(int(idx), '<unk>')\n",
    "\n",
    "def cap_to_wvec(vocab,cap):#将文本描述转换成向量\n",
    "    cap.replace(\",\",\"\")\n",
    "    cap.replace(\".\",\"\")\n",
    "    cap=cap.split()\n",
    "    res=[]\n",
    "    for word in cap:\n",
    "        if word in vocab.keys():\n",
    "            res.append(vocab[word])\n",
    "        else: #不在字典的词\n",
    "            res.append(vocab['<unk>'])\n",
    "    return res\n",
    "\n",
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, dataset_path, vocab_path, split, captions_per_image=1, max_len=93, transform=None):\n",
    "\n",
    "        self.split = split\n",
    "        assert self.split in {'train', 'test'}\n",
    "        self.cpi = captions_per_image\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # 载入数据集\n",
    "        with open(dataset_path, 'r') as f:\n",
    "            self.data = json.load(f) #key是图片名字 value是描述\n",
    "            self.data_img=list(self.data.keys())\n",
    "        # 载入词典\n",
    "        with open(vocab_path, 'r') as f:\n",
    "            self.vocab = json.load(f)\n",
    "\n",
    "        # PyTorch图像预处理流程\n",
    "        self.transform = transform\n",
    "\n",
    "        # Total number of datapoints\n",
    "        self.dataset_size = len(self.data_img)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 第i个文本描述对应第(i // captions_per_image)张图片\n",
    "        img = Image.open(img_path+\"/\"+self.data_img[i]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        c_vec=cap_to_wvec(self.vocab,self.data[self.data_img[i]])\n",
    "        #加入起始和结束标志\n",
    "        c_vec = [self.vocab['<start>']] + c_vec + [self.vocab['<end>']]\n",
    "        caplen = len(c_vec)\n",
    "        caption = torch.LongTensor(c_vec+ [self.vocab['<pad>']] * (self.max_len + 2 - caplen))\n",
    "        \n",
    "        return img, caption, caplen\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    \n",
    "def generate_sentence(model_output, idx_to_word):\n",
    "    # 选择概率最高的词汇索引\n",
    "    predicted_indices = torch.argmax(model_output, dim=-1)\n",
    "    \n",
    "    # 将索引转换为单词\n",
    "    generated_words = [idx_to_word[idx.item()] for idx in predicted_indices]\n",
    "    \n",
    "    # 连接单词生成句子\n",
    "    sentence = ' '.join(generated_words)\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, BertModel, BertConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import math\n",
    "\n",
    "class Img2TxtModel(nn.Module):\n",
    "    def __init__(self, vit_model_name, transformer_config, vocab_size):\n",
    "        super(Img2TxtModel, self).__init__()\n",
    "        # ViT模型作为编码器\n",
    "        self.encoder = ViTModel.from_pretrained(vit_model_name)\n",
    "\n",
    "        # Transformer解码器配置\n",
    "        transformer_config = BertConfig(vocab_size=vocab_size, is_decoder=True,  add_cross_attention=True)\n",
    "        self.decoder = BertModel(transformer_config)\n",
    "\n",
    "        # 预测每个词的线性层\n",
    "        self.vocab_size = vocab_size\n",
    "        self.fc = nn.Linear(transformer_config.hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, max_length=95, start_token_id=154):\n",
    "        # 获取图像特征\n",
    "        encoder_outputs = self.encoder(pixel_values=input_ids).last_hidden_state\n",
    "\n",
    "        # 初始化解码器输入为<start>标记\n",
    "        decoder_input_ids = torch.full((input_ids.size(0), 1), start_token_id).to(input_ids.device)\n",
    "        \n",
    "        # 存储所有时间步的logits\n",
    "        all_logits = []\n",
    "\n",
    "        for step in range(max_length):\n",
    "            # 获取解码器输出\n",
    "            decoder_outputs = self.decoder(\n",
    "                input_ids=decoder_input_ids, \n",
    "                encoder_hidden_states=encoder_outputs\n",
    "            ).last_hidden_state\n",
    "\n",
    "            # 预测下一个词\n",
    "            next_word_logits = self.fc(decoder_outputs[:, -1, :])\n",
    "            all_logits.append(next_word_logits.unsqueeze(1))\n",
    "            next_word_id = next_word_logits.argmax(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            # 将预测的词添加到解码器输入中\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, next_word_id], dim=-1)\n",
    "        \n",
    "        return decoder_input_ids ,torch.cat(all_logits, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Epoch [1/10], Batch [1/10155], Loss: 5.196713924407959\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "def evaluate(test_loader, model):\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    generated_captions = []\n",
    "    actual_captions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, captions, caplens in test_loader:\n",
    "            input_ids = images\n",
    "            outputs = model(input_ids, start_token_id = test_dataset.vocab['<start>'])\n",
    "            outputs = nn.functional.softmax(outputs, dim=-1)\n",
    "            predicted_indices = outputs.argmax(dim=-1)\n",
    "            for i in range(predicted_indices.shape[0]):\n",
    "                # 生成字幕\n",
    "                gen_caption = [idx_to_word(idx, test_dataset.vocab) for idx in predicted_indices[i]]\n",
    "                print(gen_caption)\n",
    "                # 移除 <start> 和 <end>\n",
    "                if '<start>' in gen_caption:\n",
    "                    gen_caption = gen_caption[1:]  # 移除第一个元素 (<start>)\n",
    "                if '<end>' in gen_caption:\n",
    "                    gen_caption = gen_caption[:gen_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "                \n",
    "                generated_captions.append(' '.join(gen_caption))\n",
    "\n",
    "                # 真实字幕\n",
    "                act_caption = [idx_to_word(idx, test_dataset.vocab) for idx in captions[i]]\n",
    "                # print(act_caption)\n",
    "                # 移除 <start> 和 <end>\n",
    "                if '<start>' in act_caption:\n",
    "                    act_caption = act_caption[1:]  # 移除第一个元素 (<start>)\n",
    "                if '<end>' in act_caption:\n",
    "                    act_caption = act_caption[:act_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "                \n",
    "                actual_captions.append([' '.join(act_caption)])\n",
    "\n",
    "        # 计算BLEU分数\n",
    "        bleu4 = corpus_bleu(actual_captions, generated_captions, weights=(0.25,0.25,0.25,0.25))\n",
    "        model.train()\n",
    "    return bleu4\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    # 这里可以添加其他必要的转换，如归一化等\n",
    "])\n",
    "\n",
    "# 假设您已经定义了dataset_path和vocab_path\n",
    "dataset = ImageTextDataset(train_json_path, vocab_path, split='train', transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "vocab_size = len(dataset.vocab)\n",
    "vit_model_name = 'google/vit-base-patch16-224-in21k'\n",
    "transformer_config = BertConfig()\n",
    "\n",
    "# 初始化模型\n",
    "model = Img2TxtModel(vit_model_name, transformer_config, vocab_size)\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab['<pad>'])\n",
    "\n",
    "test_dataset = ImageTextDataset(test_json_path, vocab_path, split='test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "# 设定训练周期\n",
    "num_epochs = 10\n",
    "best_bleu_score = 0.0  # 初始化最高BLEU分数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, captions, caplens) in enumerate(data_loader):\n",
    "        # 假设您的ViT模型接受标准化的图像张量作为输入\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        input_ids = images\n",
    "\n",
    "        # 前向传播\n",
    "        outputs, outputs_logits = model(input_ids, start_token_id = test_dataset.vocab['<start>'])\n",
    "\n",
    "        outputs_logits = outputs_logits.permute(0, 2, 1)\n",
    "        # 计算损失，outputs需要调整以适配损失函数的要求\n",
    "        loss = criterion(outputs_logits, captions)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(i+1) % 1 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(data_loader)}], Loss: {loss.item()}\")\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            bleu4 = evaluate(test_loader, model)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(data_loader)}], Loss: {loss.item()}, BLEU Score: {bleu4}\")\n",
    "\n",
    "            # 如果BLEU分数是新的最高分，则保存模型\n",
    "            if bleu4 > best_bleu_score:\n",
    "                best_bleu_score = bleu4\n",
    "                save_path = f\"model/best_model_epoch_{epoch+1}_batch_{i+1}.pth\"\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'batch': i,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'bleu_score': bleu4,\n",
    "                }, save_path)\n",
    "                print(f\"New best model saved to {save_path} with BLEU score {bleu4}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“chat_venv”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/Project/CodeProject/nlp/LLM/chat_venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model.eval()  # 将模型设置为评估模式\n",
    "generated_captions = []\n",
    "actual_captions = []\n",
    "\n",
    "test_dataset = ImageTextDataset(test_json_path, vocab_path, split='test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def idx_to_word(idx, vocab):\n",
    "    reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "    return reverse_vocab.get(idx, '<unk>')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, captions, caplens in test_loader:\n",
    "        input_ids = images\n",
    "        decoder_input_ids = captions\n",
    "        decoder_attention_mask = (captions != test_dataset.vocab['<pad>']).type(torch.uint8)\n",
    "\n",
    "        # 前向传播，生成字幕\n",
    "        outputs = model(input_ids, decoder_input_ids, decoder_attention_mask)\n",
    "\n",
    "        # 选择概率最高的词汇\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=-1)\n",
    "        predicted_indices = outputs.argmax(dim=-1)\n",
    "        \n",
    "        for i in range(predicted_indices.shape[0]):\n",
    "            # 生成字幕\n",
    "            gen_caption = [idx_to_word(idx, test_dataset.vocab) for idx in predicted_indices[i]]\n",
    "            # 移除 <start> 和 <end>\n",
    "            if '<start>' in gen_caption:\n",
    "                gen_caption = gen_caption[1:]  # 移除第一个元素 (<start>)\n",
    "            if '<end>' in gen_caption:\n",
    "                gen_caption = gen_caption[:gen_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "            generated_captions.append(' '.join(gen_caption))\n",
    "\n",
    "            # 真实字幕\n",
    "            act_caption = [idx_to_word(idx, test_dataset.vocab) for idx in captions[i]]\n",
    "            # 移除 <start> 和 <end>\n",
    "            if '<start>' in act_caption:\n",
    "                act_caption = act_caption[1:]  # 移除第一个元素 (<start>)\n",
    "            if '<end>' in act_caption:\n",
    "                act_caption = act_caption[:act_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "            actual_captions.append([' '.join(act_caption)])\n",
    "\n",
    "# 计算BLEU分数\n",
    "bleu_score = corpus_bleu(actual_captions, generated_captions)\n",
    "print(f\"BLEU score on test dataset: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“chat_venv”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/Project/CodeProject/nlp/LLM/chat_venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
