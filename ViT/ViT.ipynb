{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTFeatureExtractor, BertTokenizer\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "dataset='deepfashion-multimodal'\n",
    "img_path = f'data/{dataset}/images'\n",
    "train_json_path= f'data/{dataset}/train_captions.json'\n",
    "test_json_path= f'data/{dataset}/test_captions.json'\n",
    "vocab_path = f'data/{dataset}/vocab.json'\n",
    "\n",
    "def idx_to_word(idx, vocab):#将向量转化为文本描述\n",
    "    reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "    return reverse_vocab.get(int(idx), '<unk>')\n",
    "\n",
    "def cap_to_wvec(vocab,cap):#将文本描述转换成向量\n",
    "    cap.replace(\",\",\"\")\n",
    "    cap.replace(\".\",\"\")\n",
    "    cap=cap.split()\n",
    "    res=[]\n",
    "    for word in cap:\n",
    "        if word in vocab.keys():\n",
    "            res.append(vocab[word])\n",
    "        else: #不在字典的词\n",
    "            res.append(vocab['<unk>'])\n",
    "    return res\n",
    "\n",
    "def filter_cut_useless_words(sent, filterd_words):\n",
    "    res=[]\n",
    "    for w in sent:\n",
    "        if w not in filterd_words:\n",
    "            res.append(w)\n",
    "        else:\n",
    "            if w==155:\n",
    "                return res\n",
    "\n",
    "def get_BLEU_score(cands, refs): #获取BLEU分数\n",
    "    multiple_refs = []\n",
    "    for idx in range(len(refs)):\n",
    "        multiple_refs.append(refs[(idx//1)*1 : (idx//1)*1+1])#每个候选文本对应cpi==1条参考文本\n",
    "    bleu4 = corpus_bleu(multiple_refs, cands, weights=(0.25,0.25,0.25,0.25))\n",
    "    return bleu4\n",
    "\n",
    "def cider_d(reference_list, candidate_list, n=4):\n",
    "    def count_ngrams(tokens, n):\n",
    "        ngrams = []\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i+n])\n",
    "            ngrams.append(ngram)\n",
    "        return ngrams\n",
    "\n",
    "    def compute_cider_d(reference_list, candidate_list, n):\n",
    "        cider_d_scores = []\n",
    "        for refs, cand in zip(reference_list, candidate_list):\n",
    "            cider_d_score = 0.0\n",
    "            for i in range(1, n + 1):\n",
    "                cand_ngrams = count_ngrams(cand, i)\n",
    "                ref_ngrams_list = [count_ngrams(ref, i) for ref in refs]\n",
    "\n",
    "                total_ref_ngrams = [ngram for ref_ngrams in ref_ngrams_list for ngram in ref_ngrams]\n",
    "\n",
    "                count_cand = 0\n",
    "                count_clip = 0\n",
    "\n",
    "                for ngram in cand_ngrams:\n",
    "                    count_cand += 1\n",
    "                    if ngram in total_ref_ngrams:\n",
    "                        count_clip += 1\n",
    "\n",
    "                precision = count_clip / count_cand if count_cand > 0 else 0.0\n",
    "                recall = count_clip / len(total_ref_ngrams) if len(total_ref_ngrams) > 0 else 0.0\n",
    "\n",
    "                beta = 1.0\n",
    "                f_score = (1 + beta**2) * precision * recall / (beta**2 * precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "                cider_d_score += f_score\n",
    "\n",
    "            cider_d_score /= n\n",
    "            cider_d_scores.append(cider_d_score)\n",
    "\n",
    "        return cider_d_scores\n",
    "\n",
    "    reference_tokens_list = reference_list\n",
    "    candidate_tokens_list = candidate_list\n",
    "\n",
    "    scores = compute_cider_d(reference_tokens_list, candidate_tokens_list, n)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "def spice(reference_list, candidate_list, idf=None, beta=3):\n",
    "    def tokenize(sentence):\n",
    "        return sentence.lower().split()\n",
    "\n",
    "    def count_ngrams(tokens, n):\n",
    "        ngrams = []\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i+n])\n",
    "            ngrams.append(ngram)\n",
    "        return ngrams\n",
    "\n",
    "    def compute_spice_score(reference, candidate, idf, beta):\n",
    "        reference_tokens = reference\n",
    "        candidate_tokens = candidate\n",
    "\n",
    "        reference_ngrams = [count_ngrams(reference_tokens, i) for i in range(1, beta + 1)]\n",
    "        candidate_ngrams = [count_ngrams(candidate_tokens, i) for i in range(1, beta + 1)]\n",
    "\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        for i in range(beta):\n",
    "            common_ngrams = set(candidate_ngrams[i]) & set(reference_ngrams[i])\n",
    "\n",
    "            precision = len(common_ngrams) / len(candidate_ngrams[i]) if len(candidate_ngrams[i]) > 0 else 0.0\n",
    "            recall = len(common_ngrams) / len(reference_ngrams[i]) if len(reference_ngrams[i]) > 0 else 0.0\n",
    "\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "        precision_avg = np.mean(precision_scores)\n",
    "        recall_avg = np.mean(recall_scores)\n",
    "\n",
    "        spice_score = (precision_avg * recall_avg) / (precision_avg + recall_avg) if precision_avg + recall_avg > 0 else 0.0\n",
    "\n",
    "        if idf:\n",
    "            spice_score *= np.exp(np.sum([idf[token] for token in common_ngrams]) / len(candidate_tokens))\n",
    "\n",
    "        return spice_score\n",
    "\n",
    "    if idf is None:\n",
    "        idf = {}\n",
    "\n",
    "    spice_scores = []\n",
    "\n",
    "    for reference, candidate in zip(reference_list, candidate_list):\n",
    "        spice_score = compute_spice_score(reference, candidate, idf, beta)\n",
    "        spice_scores.append(spice_score)\n",
    "\n",
    "    return np.mean(spice_scores)\n",
    "\n",
    "def wvec_to_capls(vocab,wvec):#将向量转换成文本描述\n",
    "    res=[]\n",
    "    for word in wvec:\n",
    "        for key,value in vocab.items():\n",
    "            if value==word and key not in ['<start>','<end>','<pad>','<unk>']:\n",
    "                res.append(key)\n",
    "    return res\n",
    "\n",
    "def wvec_to_cap(vocab,wvec):#将向量转换成文本描述\n",
    "    res=[]\n",
    "    for word in wvec:\n",
    "        for key,value in vocab.items():\n",
    "            if value==word and key not in ['<start>','<end>','<pad>','<unk>']:\n",
    "                res.append(key)\n",
    "    res=\" \".join(res)\n",
    "    return res\n",
    "\n",
    "def get_CIDER_D_score(vocab,cands, refs): #获得CIDER-D分数\n",
    "    refs_ = [wvec_to_capls(vocab,ref) for ref in refs]\n",
    "    cands_ = [wvec_to_capls(vocab,cand) for cand in cands]\n",
    "    return cider_d(refs_, cands_)\n",
    "\n",
    "def get_SPICE_score(vocab,cands, refs): #获得SPICE分数\n",
    "    refs_ = [wvec_to_cap(vocab,ref) for ref in refs]\n",
    "    cands_ = [wvec_to_cap(vocab,cand) for cand in cands]\n",
    "    return spice(refs_, cands_)\n",
    "\n",
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, dataset_path, vocab_path, split, captions_per_image=6, max_len=93, transform=None):\n",
    "\n",
    "        self.split = split\n",
    "        assert self.split in {'train', 'test'}\n",
    "        self.cpi = captions_per_image\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # 载入数据集\n",
    "        with open(dataset_path, 'r') as f:\n",
    "            self.data = json.load(f) #key是图片名字 value是描述\n",
    "            self.data_img=list(self.data.keys())\n",
    "        # 载入词典\n",
    "        with open(vocab_path, 'r') as f:\n",
    "            self.vocab = json.load(f)\n",
    "\n",
    "        # PyTorch图像预处理流程\n",
    "        self.transform = transform\n",
    "\n",
    "        # Total number of datapoints\n",
    "        self.dataset_size = len(self.data_img)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 第i个文本描述对应第(i // captions_per_image)张图片\n",
    "        img = Image.open(img_path+\"/\"+self.data_img[i]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        c_vec=cap_to_wvec(self.vocab,self.data[self.data_img[i]])\n",
    "        #加入起始和结束标志\n",
    "        c_vec = [self.vocab['<start>']] + c_vec + [self.vocab['<end>']]\n",
    "        caplen = len(c_vec)\n",
    "        caption = torch.LongTensor(c_vec+ [self.vocab['<pad>']] * (self.max_len + 2 - caplen))\n",
    "        \n",
    "        return img, caption, caplen\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, BertModel, BertConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Img2TxtModel(nn.Module):\n",
    "    def __init__(self, vit_model_name, transformer_config, vocab_size):\n",
    "        super(Img2TxtModel, self).__init__()\n",
    "        # ViT模型作为编码器\n",
    "        self.encoder = ViTModel.from_pretrained(vit_model_name)\n",
    "\n",
    "        # Transformer解码器配置\n",
    "        transformer_config = BertConfig(vocab_size=vocab_size, num_hidden_layers=1, is_decoder=True,  add_cross_attention=True)\n",
    "        self.decoder = BertModel(transformer_config)\n",
    "\n",
    "        # 预测每个词的线性层\n",
    "        self.vocab_size = vocab_size\n",
    "        self.fc = nn.Linear(transformer_config.hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids, decoder_input_ids, decoder_attention_mask):\n",
    "        # 通过ViT编码器获取图像特征\n",
    "        encoder_outputs = self.encoder(pixel_values=input_ids).last_hidden_state\n",
    "\n",
    "        # 将图像特征作为解码器的输入\n",
    "        decoder_outputs = self.decoder(input_ids=decoder_input_ids, \n",
    "                                       attention_mask=decoder_attention_mask,\n",
    "                                       encoder_hidden_states=encoder_outputs).last_hidden_state\n",
    "\n",
    "        # 预测下一个词\n",
    "        prediction_scores = self.fc(decoder_outputs)\n",
    "        return prediction_scores\n",
    "\n",
    "    def generate_text(self, input_ids, max_length=95, start_token_id=154):\n",
    "        # 获取图像特征\n",
    "        encoder_outputs = self.encoder(pixel_values=input_ids).last_hidden_state\n",
    "\n",
    "        # 初始化解码器输入为<start>标记\n",
    "        decoder_input_ids = torch.full((input_ids.size(0), 1), start_token_id).to(input_ids.device)\n",
    "        \n",
    "        # 存储所有时间步的logits\n",
    "        all_logits = []\n",
    "\n",
    "        for step in range(max_length):\n",
    "            # 获取解码器输出\n",
    "            decoder_outputs = self.decoder(\n",
    "                input_ids=decoder_input_ids, \n",
    "                encoder_hidden_states=encoder_outputs\n",
    "            ).last_hidden_state\n",
    "\n",
    "            # 预测下一个词\n",
    "            next_word_logits = self.fc(decoder_outputs[:, -1, :])\n",
    "            all_logits.append(next_word_logits.unsqueeze(1))\n",
    "            next_word_id = next_word_logits.argmax(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            # 将预测的词添加到解码器输入中\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, next_word_id], dim=-1)\n",
    "        \n",
    "        return decoder_input_ids ,torch.cat(all_logits, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Epoch [1/10], Batch [100/3385], Loss: 1.506847620010376\n",
      "Epoch [1/10], Batch [200/3385], Loss: 1.0654538869857788\n",
      "Epoch [1/10], Batch [300/3385], Loss: 0.720127284526825\n",
      "Epoch [1/10], Batch [400/3385], Loss: 0.7672491669654846\n",
      "Epoch [1/10], Batch [500/3385], Loss: 0.6676333546638489\n",
      "Epoch [1/10], Batch [600/3385], Loss: 0.7424653172492981\n",
      "Epoch [1/10], Batch [700/3385], Loss: 0.526539146900177\n",
      "Epoch [1/10], Batch [800/3385], Loss: 0.5412440896034241\n",
      "Epoch [1/10], Batch [900/3385], Loss: 0.5988483428955078\n",
      "Epoch [1/10], Batch [900/3385], Loss: 0.5988483428955078, BLEU Score: 0.6259826859669076\n",
      "New best model saved to model/best_model_epoch_1_batch_900.pth with BLEU score 0.6259826859669076\n",
      "Epoch [1/10], Batch [1000/3385], Loss: 0.6830837726593018\n",
      "Epoch [1/10], Batch [1100/3385], Loss: 0.6536044478416443\n",
      "Epoch [1/10], Batch [1200/3385], Loss: 0.6345134973526001\n",
      "Epoch [1/10], Batch [1300/3385], Loss: 0.6075872182846069\n",
      "Epoch [1/10], Batch [1400/3385], Loss: 0.6370975375175476\n",
      "Epoch [1/10], Batch [1500/3385], Loss: 0.5964183211326599\n",
      "Epoch [1/10], Batch [1600/3385], Loss: 0.633446455001831\n",
      "Epoch [1/10], Batch [1700/3385], Loss: 0.4941997230052948\n",
      "Epoch [1/10], Batch [1800/3385], Loss: 0.6094977855682373\n",
      "Epoch [1/10], Batch [1800/3385], Loss: 0.6094977855682373, BLEU Score: 0.6499761614377776\n",
      "New best model saved to model/best_model_epoch_1_batch_1800.pth with BLEU score 0.6499761614377776\n",
      "Epoch [1/10], Batch [1900/3385], Loss: 0.5010225772857666\n",
      "Epoch [1/10], Batch [2000/3385], Loss: 0.5958297252655029\n",
      "Epoch [1/10], Batch [2100/3385], Loss: 0.5294401049613953\n",
      "Epoch [1/10], Batch [2200/3385], Loss: 0.4647580087184906\n",
      "Epoch [1/10], Batch [2300/3385], Loss: 0.6333135962486267\n",
      "Epoch [1/10], Batch [2400/3385], Loss: 0.5327613949775696\n",
      "Epoch [1/10], Batch [2500/3385], Loss: 0.5936553478240967\n",
      "Epoch [1/10], Batch [2600/3385], Loss: 0.5662683248519897\n",
      "Epoch [1/10], Batch [2700/3385], Loss: 0.4893517792224884\n",
      "Epoch [1/10], Batch [2700/3385], Loss: 0.4893517792224884, BLEU Score: 0.6273520776805721\n",
      "Epoch [1/10], Batch [2800/3385], Loss: 0.5826975107192993\n",
      "Epoch [1/10], Batch [2900/3385], Loss: 0.5940765738487244\n",
      "Epoch [1/10], Batch [3000/3385], Loss: 0.45800718665122986\n",
      "Epoch [1/10], Batch [3100/3385], Loss: 0.4425952732563019\n",
      "Epoch [1/10], Batch [3200/3385], Loss: 0.4501250982284546\n",
      "Epoch [1/10], Batch [3300/3385], Loss: 0.5157708525657654\n",
      "Epoch [2/10], Batch [100/3385], Loss: 0.46476876735687256\n",
      "Epoch [2/10], Batch [200/3385], Loss: 0.5956483483314514\n",
      "Epoch [2/10], Batch [300/3385], Loss: 0.4944517910480499\n",
      "Epoch [2/10], Batch [400/3385], Loss: 0.46747153997421265\n",
      "Epoch [2/10], Batch [500/3385], Loss: 0.5078564286231995\n",
      "Epoch [2/10], Batch [600/3385], Loss: 0.49568527936935425\n",
      "Epoch [2/10], Batch [700/3385], Loss: 0.48543137311935425\n",
      "Epoch [2/10], Batch [800/3385], Loss: 0.5878289341926575\n",
      "Epoch [2/10], Batch [900/3385], Loss: 0.3999037444591522\n",
      "Epoch [2/10], Batch [900/3385], Loss: 0.3999037444591522, BLEU Score: 0.6306047781805396\n",
      "Epoch [2/10], Batch [1000/3385], Loss: 0.4190608859062195\n",
      "Epoch [2/10], Batch [1100/3385], Loss: 0.6893869638442993\n",
      "Epoch [2/10], Batch [1200/3385], Loss: 0.45286086201667786\n",
      "Epoch [2/10], Batch [1300/3385], Loss: 0.5955387353897095\n",
      "Epoch [2/10], Batch [1400/3385], Loss: 0.48197141289711\n",
      "Epoch [2/10], Batch [1500/3385], Loss: 0.5032705068588257\n",
      "Epoch [2/10], Batch [1600/3385], Loss: 0.5179394483566284\n",
      "Epoch [2/10], Batch [1700/3385], Loss: 0.5289398431777954\n",
      "Epoch [2/10], Batch [1800/3385], Loss: 0.48149487376213074\n",
      "Epoch [2/10], Batch [1800/3385], Loss: 0.48149487376213074, BLEU Score: 0.5952451904844176\n",
      "Epoch [2/10], Batch [1900/3385], Loss: 0.5015336871147156\n",
      "Epoch [2/10], Batch [2000/3385], Loss: 0.41118180751800537\n",
      "Epoch [2/10], Batch [2100/3385], Loss: 0.6792697906494141\n",
      "Epoch [2/10], Batch [2200/3385], Loss: 0.466006875038147\n",
      "Epoch [2/10], Batch [2300/3385], Loss: 0.492031991481781\n",
      "Epoch [2/10], Batch [2400/3385], Loss: 0.4278179109096527\n",
      "Epoch [2/10], Batch [2500/3385], Loss: 0.5117957592010498\n",
      "Epoch [2/10], Batch [2600/3385], Loss: 0.46907398104667664\n",
      "Epoch [2/10], Batch [2700/3385], Loss: 0.599402129650116\n",
      "Epoch [2/10], Batch [2700/3385], Loss: 0.599402129650116, BLEU Score: 0.6457694776801362\n",
      "Epoch [2/10], Batch [2800/3385], Loss: 0.5363532304763794\n",
      "Epoch [2/10], Batch [2900/3385], Loss: 0.5502106547355652\n",
      "Epoch [2/10], Batch [3000/3385], Loss: 0.5129263401031494\n",
      "Epoch [2/10], Batch [3100/3385], Loss: 0.4920698404312134\n",
      "Epoch [2/10], Batch [3200/3385], Loss: 0.47866472601890564\n",
      "Epoch [2/10], Batch [3300/3385], Loss: 0.525836169719696\n",
      "Epoch [3/10], Batch [100/3385], Loss: 0.4898045063018799\n",
      "Epoch [3/10], Batch [200/3385], Loss: 0.5084397196769714\n",
      "Epoch [3/10], Batch [300/3385], Loss: 0.4473249614238739\n",
      "Epoch [3/10], Batch [400/3385], Loss: 0.4763574004173279\n",
      "Epoch [3/10], Batch [500/3385], Loss: 0.5079389214515686\n",
      "Epoch [3/10], Batch [600/3385], Loss: 0.44530239701271057\n",
      "Epoch [3/10], Batch [700/3385], Loss: 0.44787898659706116\n",
      "Epoch [3/10], Batch [800/3385], Loss: 0.4493464529514313\n",
      "Epoch [3/10], Batch [900/3385], Loss: 0.4891371428966522\n",
      "Epoch [3/10], Batch [900/3385], Loss: 0.4891371428966522, BLEU Score: 0.6265277873070316\n",
      "Epoch [3/10], Batch [1000/3385], Loss: 0.44602829217910767\n",
      "Epoch [3/10], Batch [1100/3385], Loss: 0.5403011441230774\n",
      "Epoch [3/10], Batch [1200/3385], Loss: 0.4890633821487427\n",
      "Epoch [3/10], Batch [1300/3385], Loss: 0.4871854782104492\n",
      "Epoch [3/10], Batch [1400/3385], Loss: 0.4959268867969513\n",
      "Epoch [3/10], Batch [1500/3385], Loss: 0.4298979938030243\n",
      "Epoch [3/10], Batch [1600/3385], Loss: 0.5024811625480652\n",
      "Epoch [3/10], Batch [1700/3385], Loss: 0.5016076564788818\n",
      "Epoch [3/10], Batch [1800/3385], Loss: 0.4154992401599884\n",
      "Epoch [3/10], Batch [1800/3385], Loss: 0.4154992401599884, BLEU Score: 0.5135787960939046\n",
      "Epoch [3/10], Batch [1900/3385], Loss: 0.4994415044784546\n",
      "Epoch [3/10], Batch [2000/3385], Loss: 0.5580220818519592\n",
      "Epoch [3/10], Batch [2100/3385], Loss: 0.4753514528274536\n",
      "Epoch [3/10], Batch [2200/3385], Loss: 0.5234423875808716\n",
      "Epoch [3/10], Batch [2300/3385], Loss: 0.5374242663383484\n",
      "Epoch [3/10], Batch [2400/3385], Loss: 0.46420326828956604\n",
      "Epoch [3/10], Batch [2500/3385], Loss: 0.7553501129150391\n",
      "Epoch [3/10], Batch [2600/3385], Loss: 0.4739769697189331\n",
      "Epoch [3/10], Batch [2700/3385], Loss: 0.45902305841445923\n",
      "Epoch [3/10], Batch [2700/3385], Loss: 0.45902305841445923, BLEU Score: 0.5779657123842289\n",
      "Epoch [3/10], Batch [2800/3385], Loss: 0.5141093134880066\n",
      "Epoch [3/10], Batch [2900/3385], Loss: 0.5070458054542542\n",
      "Epoch [3/10], Batch [3000/3385], Loss: 0.4712170958518982\n",
      "Epoch [3/10], Batch [3100/3385], Loss: 0.42678409814834595\n",
      "Epoch [3/10], Batch [3200/3385], Loss: 0.43770480155944824\n",
      "Epoch [3/10], Batch [3300/3385], Loss: 0.4264000356197357\n",
      "Epoch [4/10], Batch [100/3385], Loss: 0.46770212054252625\n",
      "Epoch [4/10], Batch [200/3385], Loss: 0.43026411533355713\n",
      "Epoch [4/10], Batch [300/3385], Loss: 0.46422722935676575\n",
      "Epoch [4/10], Batch [400/3385], Loss: 0.4911220073699951\n",
      "Epoch [4/10], Batch [500/3385], Loss: 0.4276711344718933\n",
      "Epoch [4/10], Batch [600/3385], Loss: 0.6344284415245056\n",
      "Epoch [4/10], Batch [700/3385], Loss: 0.48250553011894226\n",
      "Epoch [4/10], Batch [800/3385], Loss: 0.4964185953140259\n",
      "Epoch [4/10], Batch [900/3385], Loss: 0.5124995112419128\n",
      "Epoch [4/10], Batch [900/3385], Loss: 0.5124995112419128, BLEU Score: 0.5957952320057779\n",
      "Epoch [4/10], Batch [1000/3385], Loss: 0.4611283242702484\n",
      "Epoch [4/10], Batch [1100/3385], Loss: 0.3852692246437073\n",
      "Epoch [4/10], Batch [1200/3385], Loss: 0.4541368782520294\n",
      "Epoch [4/10], Batch [1300/3385], Loss: 0.46968477964401245\n",
      "Epoch [4/10], Batch [1400/3385], Loss: 0.4993707835674286\n",
      "Epoch [4/10], Batch [1500/3385], Loss: 0.43745920062065125\n",
      "Epoch [4/10], Batch [1600/3385], Loss: 0.5956730246543884\n",
      "Epoch [4/10], Batch [1700/3385], Loss: 0.4268757104873657\n",
      "Epoch [4/10], Batch [1800/3385], Loss: 0.39837056398391724\n",
      "Epoch [4/10], Batch [1800/3385], Loss: 0.39837056398391724, BLEU Score: 0.5280371000845845\n",
      "Epoch [4/10], Batch [1900/3385], Loss: 0.5282601118087769\n",
      "Epoch [4/10], Batch [2000/3385], Loss: 0.4508409798145294\n",
      "Epoch [4/10], Batch [2100/3385], Loss: 0.44163599610328674\n",
      "Epoch [4/10], Batch [2200/3385], Loss: 0.4085763990879059\n",
      "Epoch [4/10], Batch [2300/3385], Loss: 0.42351624369621277\n",
      "Epoch [4/10], Batch [2400/3385], Loss: 0.4682406485080719\n",
      "Epoch [4/10], Batch [2500/3385], Loss: 0.39348071813583374\n",
      "Epoch [4/10], Batch [2600/3385], Loss: 0.45065101981163025\n",
      "Epoch [4/10], Batch [2700/3385], Loss: 0.4543023407459259\n",
      "Epoch [4/10], Batch [2700/3385], Loss: 0.4543023407459259, BLEU Score: 0.639408653717198\n",
      "Epoch [4/10], Batch [2800/3385], Loss: 0.4714568853378296\n",
      "Epoch [4/10], Batch [2900/3385], Loss: 0.42544957995414734\n",
      "Epoch [4/10], Batch [3000/3385], Loss: 0.40744078159332275\n",
      "Epoch [4/10], Batch [3100/3385], Loss: 0.5178104639053345\n",
      "Epoch [4/10], Batch [3200/3385], Loss: 0.4387783408164978\n",
      "Epoch [4/10], Batch [3300/3385], Loss: 0.43427574634552\n",
      "Epoch [5/10], Batch [100/3385], Loss: 0.4102031886577606\n",
      "Epoch [5/10], Batch [200/3385], Loss: 0.5433588624000549\n",
      "Epoch [5/10], Batch [300/3385], Loss: 0.6278513669967651\n",
      "Epoch [5/10], Batch [400/3385], Loss: 0.4025243818759918\n",
      "Epoch [5/10], Batch [500/3385], Loss: 0.44197726249694824\n",
      "Epoch [5/10], Batch [600/3385], Loss: 0.43441057205200195\n",
      "Epoch [5/10], Batch [700/3385], Loss: 0.4190601706504822\n",
      "Epoch [5/10], Batch [800/3385], Loss: 0.4117361605167389\n",
      "Epoch [5/10], Batch [900/3385], Loss: 0.4667566418647766\n",
      "Epoch [5/10], Batch [900/3385], Loss: 0.4667566418647766, BLEU Score: 0.657183633386523\n",
      "New best model saved to model/best_model_epoch_5_batch_900.pth with BLEU score 0.657183633386523\n",
      "Epoch [5/10], Batch [1000/3385], Loss: 0.451249897480011\n",
      "Epoch [5/10], Batch [1100/3385], Loss: 0.49214866757392883\n",
      "Epoch [5/10], Batch [1200/3385], Loss: 0.43253254890441895\n",
      "Epoch [5/10], Batch [1300/3385], Loss: 0.5628259181976318\n",
      "Epoch [5/10], Batch [1400/3385], Loss: 0.37490856647491455\n",
      "Epoch [5/10], Batch [1500/3385], Loss: 0.499080628156662\n",
      "Epoch [5/10], Batch [1600/3385], Loss: 0.4075632095336914\n",
      "Epoch [5/10], Batch [1700/3385], Loss: 0.45617181062698364\n",
      "Epoch [5/10], Batch [1800/3385], Loss: 0.4551757872104645\n",
      "Epoch [5/10], Batch [1800/3385], Loss: 0.4551757872104645, BLEU Score: 0.6360896363451195\n",
      "Epoch [5/10], Batch [1900/3385], Loss: 0.4530367851257324\n",
      "Epoch [5/10], Batch [2000/3385], Loss: 0.4712294340133667\n",
      "Epoch [5/10], Batch [2100/3385], Loss: 0.5259047746658325\n",
      "Epoch [5/10], Batch [2200/3385], Loss: 0.551623523235321\n",
      "Epoch [5/10], Batch [2300/3385], Loss: 0.4146064519882202\n",
      "Epoch [5/10], Batch [2400/3385], Loss: 0.5055832862854004\n",
      "Epoch [5/10], Batch [2500/3385], Loss: 0.48640984296798706\n",
      "Epoch [5/10], Batch [2600/3385], Loss: 0.43123242259025574\n",
      "Epoch [5/10], Batch [2700/3385], Loss: 0.4834398329257965\n",
      "Epoch [5/10], Batch [2700/3385], Loss: 0.4834398329257965, BLEU Score: 0.6066966294284946\n",
      "Epoch [5/10], Batch [2800/3385], Loss: 0.37496018409729004\n",
      "Epoch [5/10], Batch [2900/3385], Loss: 0.41133013367652893\n",
      "Epoch [5/10], Batch [3000/3385], Loss: 0.4146104156970978\n",
      "Epoch [5/10], Batch [3100/3385], Loss: 0.46421417593955994\n",
      "Epoch [5/10], Batch [3200/3385], Loss: 0.3927662670612335\n",
      "Epoch [5/10], Batch [3300/3385], Loss: 0.4173738360404968\n",
      "Epoch [6/10], Batch [100/3385], Loss: 0.45240864157676697\n",
      "Epoch [6/10], Batch [200/3385], Loss: 0.4844304323196411\n",
      "Epoch [6/10], Batch [300/3385], Loss: 0.5530915260314941\n",
      "Epoch [6/10], Batch [400/3385], Loss: 0.45176994800567627\n",
      "Epoch [6/10], Batch [500/3385], Loss: 0.4052988886833191\n",
      "Epoch [6/10], Batch [600/3385], Loss: 0.42596396803855896\n",
      "Epoch [6/10], Batch [700/3385], Loss: 0.4326914846897125\n",
      "Epoch [6/10], Batch [800/3385], Loss: 0.4937518835067749\n",
      "Epoch [6/10], Batch [900/3385], Loss: 0.4936274290084839\n",
      "Epoch [6/10], Batch [900/3385], Loss: 0.4936274290084839, BLEU Score: 0.6099578034593809\n",
      "Epoch [6/10], Batch [1000/3385], Loss: 0.4961879849433899\n",
      "Epoch [6/10], Batch [1100/3385], Loss: 0.41622450947761536\n",
      "Epoch [6/10], Batch [1200/3385], Loss: 0.39469578862190247\n",
      "Epoch [6/10], Batch [1300/3385], Loss: 0.4247240126132965\n",
      "Epoch [6/10], Batch [1400/3385], Loss: 0.5799625515937805\n",
      "Epoch [6/10], Batch [1500/3385], Loss: 0.4860732853412628\n",
      "Epoch [6/10], Batch [1600/3385], Loss: 0.4164365828037262\n",
      "Epoch [6/10], Batch [1700/3385], Loss: 0.48073866963386536\n",
      "Epoch [6/10], Batch [1800/3385], Loss: 0.3841512203216553\n",
      "Epoch [6/10], Batch [1800/3385], Loss: 0.3841512203216553, BLEU Score: 0.5947547813004236\n",
      "Epoch [6/10], Batch [1900/3385], Loss: 0.4323679506778717\n",
      "Epoch [6/10], Batch [2000/3385], Loss: 0.49509772658348083\n",
      "Epoch [6/10], Batch [2100/3385], Loss: 0.49317845702171326\n",
      "Epoch [6/10], Batch [2200/3385], Loss: 0.4318307340145111\n",
      "Epoch [6/10], Batch [2300/3385], Loss: 0.46929118037223816\n",
      "Epoch [6/10], Batch [2400/3385], Loss: 0.386508971452713\n",
      "Epoch [6/10], Batch [2500/3385], Loss: 0.3676878809928894\n",
      "Epoch [6/10], Batch [2600/3385], Loss: 0.39446550607681274\n",
      "Epoch [6/10], Batch [2700/3385], Loss: 0.525370717048645\n",
      "Epoch [6/10], Batch [2700/3385], Loss: 0.525370717048645, BLEU Score: 0.6140873664042887\n",
      "Epoch [6/10], Batch [2800/3385], Loss: 0.3571808338165283\n",
      "Epoch [6/10], Batch [2900/3385], Loss: 0.4875484108924866\n",
      "Epoch [6/10], Batch [3000/3385], Loss: 0.4953784942626953\n",
      "Epoch [6/10], Batch [3100/3385], Loss: 0.4420313239097595\n",
      "Epoch [6/10], Batch [3200/3385], Loss: 0.39990687370300293\n",
      "Epoch [6/10], Batch [3300/3385], Loss: 0.4982645809650421\n",
      "Epoch [7/10], Batch [100/3385], Loss: 0.4385923147201538\n",
      "Epoch [7/10], Batch [200/3385], Loss: 0.43997159600257874\n",
      "Epoch [7/10], Batch [300/3385], Loss: 0.5116627216339111\n",
      "Epoch [7/10], Batch [400/3385], Loss: 0.43550121784210205\n",
      "Epoch [7/10], Batch [500/3385], Loss: 0.4919750988483429\n",
      "Epoch [7/10], Batch [600/3385], Loss: 0.4595571756362915\n",
      "Epoch [7/10], Batch [700/3385], Loss: 0.46697908639907837\n",
      "Epoch [7/10], Batch [800/3385], Loss: 0.4819534718990326\n",
      "Epoch [7/10], Batch [900/3385], Loss: 0.3747020959854126\n",
      "Epoch [7/10], Batch [900/3385], Loss: 0.3747020959854126, BLEU Score: 0.6191507813486982\n",
      "Epoch [7/10], Batch [1000/3385], Loss: 0.4624747037887573\n",
      "Epoch [7/10], Batch [1100/3385], Loss: 0.44760662317276\n",
      "Epoch [7/10], Batch [1200/3385], Loss: 0.5016758441925049\n",
      "Epoch [7/10], Batch [1300/3385], Loss: 0.5357837677001953\n",
      "Epoch [7/10], Batch [1400/3385], Loss: 0.47158148884773254\n",
      "Epoch [7/10], Batch [1500/3385], Loss: 0.40382376313209534\n",
      "Epoch [7/10], Batch [1600/3385], Loss: 0.4869937300682068\n",
      "Epoch [7/10], Batch [1700/3385], Loss: 0.47104746103286743\n",
      "Epoch [7/10], Batch [1800/3385], Loss: 0.4044100344181061\n",
      "Epoch [7/10], Batch [1800/3385], Loss: 0.4044100344181061, BLEU Score: 0.6562587813189472\n",
      "Epoch [7/10], Batch [1900/3385], Loss: 0.5432260036468506\n",
      "Epoch [7/10], Batch [2000/3385], Loss: 0.4081021249294281\n",
      "Epoch [7/10], Batch [2100/3385], Loss: 0.39168065786361694\n",
      "Epoch [7/10], Batch [2200/3385], Loss: 0.45291900634765625\n",
      "Epoch [7/10], Batch [2300/3385], Loss: 0.5602723956108093\n",
      "Epoch [7/10], Batch [2400/3385], Loss: 0.4504901170730591\n",
      "Epoch [7/10], Batch [2500/3385], Loss: 0.42020854353904724\n",
      "Epoch [7/10], Batch [2600/3385], Loss: 0.4315740168094635\n",
      "Epoch [7/10], Batch [2700/3385], Loss: 0.42608895897865295\n",
      "Epoch [7/10], Batch [2700/3385], Loss: 0.42608895897865295, BLEU Score: 0.6368497371633002\n",
      "Epoch [7/10], Batch [2800/3385], Loss: 0.44904786348342896\n",
      "Epoch [7/10], Batch [2900/3385], Loss: 0.4278545379638672\n",
      "Epoch [7/10], Batch [3000/3385], Loss: 0.46741461753845215\n",
      "Epoch [7/10], Batch [3100/3385], Loss: 0.5061702132225037\n",
      "Epoch [7/10], Batch [3200/3385], Loss: 0.4447651207447052\n",
      "Epoch [7/10], Batch [3300/3385], Loss: 0.40045034885406494\n",
      "Epoch [8/10], Batch [100/3385], Loss: 0.43047285079956055\n",
      "Epoch [8/10], Batch [200/3385], Loss: 0.35144561529159546\n",
      "Epoch [8/10], Batch [300/3385], Loss: 0.4458153247833252\n",
      "Epoch [8/10], Batch [400/3385], Loss: 0.4366624653339386\n",
      "Epoch [8/10], Batch [500/3385], Loss: 0.5055469870567322\n",
      "Epoch [8/10], Batch [600/3385], Loss: 0.4011968672275543\n",
      "Epoch [8/10], Batch [700/3385], Loss: 0.48366671800613403\n",
      "Epoch [8/10], Batch [800/3385], Loss: 0.5047667622566223\n",
      "Epoch [8/10], Batch [900/3385], Loss: 0.482930451631546\n",
      "Epoch [8/10], Batch [900/3385], Loss: 0.482930451631546, BLEU Score: 0.6122230712176184\n",
      "Epoch [8/10], Batch [1000/3385], Loss: 0.4426495134830475\n",
      "Epoch [8/10], Batch [1100/3385], Loss: 0.5322694182395935\n",
      "Epoch [8/10], Batch [1200/3385], Loss: 0.46033889055252075\n",
      "Epoch [8/10], Batch [1300/3385], Loss: 0.47482892870903015\n",
      "Epoch [8/10], Batch [1400/3385], Loss: 0.4434620141983032\n",
      "Epoch [8/10], Batch [1500/3385], Loss: 0.4904381334781647\n",
      "Epoch [8/10], Batch [1600/3385], Loss: 0.3616958558559418\n",
      "Epoch [8/10], Batch [1700/3385], Loss: 0.37503698468208313\n",
      "Epoch [8/10], Batch [1800/3385], Loss: 0.4366777539253235\n",
      "Epoch [8/10], Batch [1800/3385], Loss: 0.4366777539253235, BLEU Score: 0.6585437255741698\n",
      "New best model saved to model/best_model_epoch_8_batch_1800.pth with BLEU score 0.6585437255741698\n",
      "Epoch [8/10], Batch [1900/3385], Loss: 0.3897594213485718\n",
      "Epoch [8/10], Batch [2000/3385], Loss: 0.40130987763404846\n",
      "Epoch [8/10], Batch [2100/3385], Loss: 0.37560680508613586\n",
      "Epoch [8/10], Batch [2200/3385], Loss: 0.444630891084671\n",
      "Epoch [8/10], Batch [2300/3385], Loss: 0.4399137496948242\n",
      "Epoch [8/10], Batch [2400/3385], Loss: 0.5606774687767029\n",
      "Epoch [8/10], Batch [2500/3385], Loss: 0.4447225332260132\n",
      "Epoch [8/10], Batch [2600/3385], Loss: 0.36013519763946533\n",
      "Epoch [8/10], Batch [2700/3385], Loss: 0.5258728861808777\n",
      "Epoch [8/10], Batch [2700/3385], Loss: 0.5258728861808777, BLEU Score: 0.6099369823315987\n",
      "Epoch [8/10], Batch [2800/3385], Loss: 0.5524425506591797\n",
      "Epoch [8/10], Batch [2900/3385], Loss: 0.49892255663871765\n",
      "Epoch [8/10], Batch [3000/3385], Loss: 0.43546628952026367\n",
      "Epoch [8/10], Batch [3100/3385], Loss: 0.4473860561847687\n",
      "Epoch [8/10], Batch [3200/3385], Loss: 0.45614057779312134\n",
      "Epoch [8/10], Batch [3300/3385], Loss: 0.4784499704837799\n",
      "Epoch [9/10], Batch [100/3385], Loss: 0.4882113039493561\n",
      "Epoch [9/10], Batch [200/3385], Loss: 0.39622798562049866\n",
      "Epoch [9/10], Batch [300/3385], Loss: 0.43471258878707886\n",
      "Epoch [9/10], Batch [400/3385], Loss: 0.5436696410179138\n",
      "Epoch [9/10], Batch [500/3385], Loss: 0.4261394441127777\n",
      "Epoch [9/10], Batch [600/3385], Loss: 0.46043333411216736\n",
      "Epoch [9/10], Batch [700/3385], Loss: 0.5166803002357483\n",
      "Epoch [9/10], Batch [800/3385], Loss: 0.5033921003341675\n",
      "Epoch [9/10], Batch [900/3385], Loss: 0.43346792459487915\n",
      "Epoch [9/10], Batch [900/3385], Loss: 0.43346792459487915, BLEU Score: 0.6411087982755627\n",
      "Epoch [9/10], Batch [1000/3385], Loss: 0.4604831337928772\n",
      "Epoch [9/10], Batch [1100/3385], Loss: 0.48319172859191895\n",
      "Epoch [9/10], Batch [1200/3385], Loss: 0.40194717049598694\n",
      "Epoch [9/10], Batch [1300/3385], Loss: 0.5072685480117798\n",
      "Epoch [9/10], Batch [1400/3385], Loss: 0.4238347113132477\n",
      "Epoch [9/10], Batch [1500/3385], Loss: 0.6097126007080078\n",
      "Epoch [9/10], Batch [1600/3385], Loss: 0.4651317596435547\n",
      "Epoch [9/10], Batch [1700/3385], Loss: 0.45657482743263245\n",
      "Epoch [9/10], Batch [1800/3385], Loss: 0.3479486107826233\n",
      "Epoch [9/10], Batch [1800/3385], Loss: 0.3479486107826233, BLEU Score: 0.6366775191183544\n",
      "Epoch [9/10], Batch [1900/3385], Loss: 0.36093080043792725\n",
      "Epoch [9/10], Batch [2000/3385], Loss: 0.371528297662735\n",
      "Epoch [9/10], Batch [2100/3385], Loss: 0.5159643888473511\n",
      "Epoch [9/10], Batch [2200/3385], Loss: 0.38837355375289917\n",
      "Epoch [9/10], Batch [2300/3385], Loss: 0.5057320594787598\n",
      "Epoch [9/10], Batch [2400/3385], Loss: 0.46596574783325195\n",
      "Epoch [9/10], Batch [2500/3385], Loss: 0.450432151556015\n",
      "Epoch [9/10], Batch [2600/3385], Loss: 0.40980589389801025\n",
      "Epoch [9/10], Batch [2700/3385], Loss: 0.4379664361476898\n",
      "Epoch [9/10], Batch [2700/3385], Loss: 0.4379664361476898, BLEU Score: 0.6150770088422075\n",
      "Epoch [9/10], Batch [2800/3385], Loss: 0.4877370297908783\n",
      "Epoch [9/10], Batch [2900/3385], Loss: 0.40075528621673584\n",
      "Epoch [9/10], Batch [3000/3385], Loss: 0.3522195816040039\n",
      "Epoch [9/10], Batch [3100/3385], Loss: 0.3765401244163513\n",
      "Epoch [9/10], Batch [3200/3385], Loss: 0.38588494062423706\n",
      "Epoch [9/10], Batch [3300/3385], Loss: 0.4325076937675476\n",
      "Epoch [10/10], Batch [100/3385], Loss: 0.4888536036014557\n",
      "Epoch [10/10], Batch [200/3385], Loss: 0.3897317051887512\n",
      "Epoch [10/10], Batch [300/3385], Loss: 0.35797613859176636\n",
      "Epoch [10/10], Batch [400/3385], Loss: 0.39244332909584045\n",
      "Epoch [10/10], Batch [500/3385], Loss: 0.42655041813850403\n",
      "Epoch [10/10], Batch [600/3385], Loss: 0.4513237178325653\n",
      "Epoch [10/10], Batch [700/3385], Loss: 0.4259300231933594\n",
      "Epoch [10/10], Batch [800/3385], Loss: 0.3846912384033203\n",
      "Epoch [10/10], Batch [900/3385], Loss: 0.407758891582489\n",
      "Epoch [10/10], Batch [900/3385], Loss: 0.407758891582489, BLEU Score: 0.6306034361402596\n",
      "Epoch [10/10], Batch [1000/3385], Loss: 0.5385867357254028\n",
      "Epoch [10/10], Batch [1100/3385], Loss: 0.46417561173439026\n",
      "Epoch [10/10], Batch [1200/3385], Loss: 0.4319520592689514\n",
      "Epoch [10/10], Batch [1300/3385], Loss: 0.36374565958976746\n",
      "Epoch [10/10], Batch [1400/3385], Loss: 0.3605068624019623\n",
      "Epoch [10/10], Batch [1500/3385], Loss: 0.4097943603992462\n",
      "Epoch [10/10], Batch [1600/3385], Loss: 0.42661750316619873\n",
      "Epoch [10/10], Batch [1700/3385], Loss: 0.4788033664226532\n",
      "Epoch [10/10], Batch [1800/3385], Loss: 0.3844136893749237\n",
      "Epoch [10/10], Batch [1800/3385], Loss: 0.3844136893749237, BLEU Score: 0.6339382113448834\n",
      "Epoch [10/10], Batch [1900/3385], Loss: 0.46550217270851135\n",
      "Epoch [10/10], Batch [2000/3385], Loss: 0.33330783247947693\n",
      "Epoch [10/10], Batch [2100/3385], Loss: 0.4416351318359375\n",
      "Epoch [10/10], Batch [2200/3385], Loss: 0.5118553042411804\n",
      "Epoch [10/10], Batch [2300/3385], Loss: 0.3825181722640991\n",
      "Epoch [10/10], Batch [2400/3385], Loss: 0.3916151523590088\n",
      "Epoch [10/10], Batch [2500/3385], Loss: 0.42515692114830017\n",
      "Epoch [10/10], Batch [2600/3385], Loss: 0.43171802163124084\n",
      "Epoch [10/10], Batch [2700/3385], Loss: 0.4633576571941376\n",
      "Epoch [10/10], Batch [2700/3385], Loss: 0.4633576571941376, BLEU Score: 0.6640697619027633\n",
      "New best model saved to model/best_model_epoch_10_batch_2700.pth with BLEU score 0.6640697619027633\n",
      "Epoch [10/10], Batch [2800/3385], Loss: 0.5012379288673401\n",
      "Epoch [10/10], Batch [2900/3385], Loss: 0.4428495466709137\n",
      "Epoch [10/10], Batch [3000/3385], Loss: 0.4523705840110779\n",
      "Epoch [10/10], Batch [3100/3385], Loss: 0.35377541184425354\n",
      "Epoch [10/10], Batch [3200/3385], Loss: 0.44981083273887634\n",
      "Epoch [10/10], Batch [3300/3385], Loss: 0.37558305263519287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "def evaluate(test_loader, model):\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    generated_captions = []\n",
    "    actual_captions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, captions, caplens in test_loader:\n",
    "            images = images.to(device)\n",
    "            input_ids = images\n",
    "            outputs,_ = model.generate_text(input_ids, max_length=95, start_token_id=test_dataset.vocab['<start>'])\n",
    "            for i in range(outputs.shape[0]):\n",
    "                # 生成字幕\n",
    "                gen_caption = [idx_to_word(idx, test_dataset.vocab) for idx in outputs[i]]\n",
    "                # print(gen_caption)\n",
    "                # 移除 <start> 和 <end>\n",
    "                if '<start>' in gen_caption:\n",
    "                    gen_caption = gen_caption[1:]  # 移除第一个元素 (<start>)\n",
    "                if '<end>' in gen_caption:\n",
    "                    gen_caption = gen_caption[:gen_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "                \n",
    "                generated_captions.append(' '.join(gen_caption))\n",
    "\n",
    "                # 真实字幕\n",
    "                act_caption = [idx_to_word(idx, test_dataset.vocab) for idx in captions[i]]\n",
    "                # print(act_caption)\n",
    "                # 移除 <start> 和 <end>\n",
    "                if '<start>' in act_caption:\n",
    "                    act_caption = act_caption[1:]  # 移除第一个元素 (<start>)\n",
    "                if '<end>' in act_caption:\n",
    "                    act_caption = act_caption[:act_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "                \n",
    "                actual_captions.append([' '.join(act_caption)])\n",
    "\n",
    "        # 计算BLEU分数\n",
    "        bleu4 = corpus_bleu(actual_captions, generated_captions, weights=(0.25,0.25,0.25,0.25))\n",
    "    model.train()\n",
    "    return bleu4\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    # 这里可以添加其他必要的转换，如归一化等\n",
    "])\n",
    "\n",
    "dataset = ImageTextDataset(train_json_path, vocab_path, split='train', transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "vocab_size = len(dataset.vocab)\n",
    "vit_model_name = 'google/vit-base-patch16-224-in21k'\n",
    "transformer_config = BertConfig()\n",
    "\n",
    "# 初始化模型\n",
    "model = Img2TxtModel(vit_model_name, transformer_config, vocab_size)\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab['<pad>'])\n",
    "\n",
    "test_dataset = ImageTextDataset(test_json_path, vocab_path, split='test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=True)\n",
    "# 设定训练周期\n",
    "num_epochs = 10\n",
    "best_bleu_score = 0.0  # 初始化最高BLEU分数\n",
    "\n",
    "# 在训练时使用\"teacher forcing\"来生成字幕\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, captions, caplens) in enumerate(data_loader):\n",
    "        # 假设您的ViT模型接受标准化的图像张量作为输入\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        input_ids = images\n",
    "\n",
    "        # 准备解码器输入\n",
    "        decoder_input_ids = captions[:, :-1]  # 删除每个字幕的最后一个单词\n",
    "        decoder_attention_mask = (decoder_input_ids != dataset.vocab['<pad>']).type(torch.uint8)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, decoder_input_ids, decoder_attention_mask)\n",
    "\n",
    "        # 计算损失，outputs需要调整以适配损失函数的要求\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), captions[:, 1:].contiguous().view(-1))\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(data_loader)}], Loss: {loss.item()}\")\n",
    "        \n",
    "        if (i + 1) % 900 == 0:\n",
    "            bleu4 = evaluate(test_loader, model)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(data_loader)}], Loss: {loss.item()}, BLEU Score: {bleu4}\")\n",
    "\n",
    "            # 如果BLEU分数是新的最高分，则保存模型\n",
    "            if bleu4 > best_bleu_score:\n",
    "                best_bleu_score = bleu4\n",
    "                save_path = f\"model/best_model_epoch_{epoch+1}_batch_{i+1}.pth\"\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'batch': i,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'bleu_score': bleu4,\n",
    "                }, save_path)\n",
    "                print(f\"New best model saved to {save_path} with BLEU score {bleu4}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "bleu4 :0.6640697619027633\n",
      "bleu4_token :0.3074786561430062\n",
      "cider_d_score :0.004119164250591897\n",
      "spice_score :0.1321016861247424\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    # 这里可以添加其他必要的转换，如归一化等\n",
    "])\n",
    "test_dataset = ImageTextDataset(test_json_path, vocab_path, split='test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "vocab_size = len(test_dataset.vocab)\n",
    "vit_model_name = 'google/vit-base-patch16-224-in21k'\n",
    "transformer_config = BertConfig()\n",
    "model = Img2TxtModel(vit_model_name, transformer_config, vocab_size)\n",
    "# 加载模型状态字典\n",
    "checkpoint = torch.load('./model/best_model_epoch_10_batch_2700.pth')\n",
    "\n",
    "# 将状态字典应用到模型实例中\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "\n",
    "generated_captions = []\n",
    "actual_captions = []\n",
    "cands = []\n",
    "refs = []\n",
    "filterd_words = set({test_dataset.vocab['<start>'], test_dataset.vocab['<end>'], test_dataset.vocab['<pad>']})\n",
    "with torch.no_grad():\n",
    "    for images, captions, caplens in test_loader:\n",
    "        images = images.to(device)\n",
    "        input_ids = images\n",
    "        outputs,_ = model.generate_text(input_ids, max_length=95, start_token_id=test_dataset.vocab['<start>'])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            gen_caption = [idx_to_word(idx, test_dataset.vocab) for idx in outputs[i]]\n",
    "            if '<start>' in gen_caption:\n",
    "                gen_caption = gen_caption[1:]  # 移除第一个元素 (<start>)\n",
    "            if '<end>' in gen_caption:\n",
    "                gen_caption = gen_caption[:gen_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "            generated_captions.append(' '.join(gen_caption))\n",
    "            act_caption = [idx_to_word(idx, test_dataset.vocab) for idx in captions[i]]\n",
    "            # 移除 <start> 和 <end>\n",
    "            if '<start>' in act_caption:\n",
    "                act_caption = act_caption[1:]  # 移除第一个元素 (<start>)\n",
    "            if '<end>' in act_caption:\n",
    "                act_caption = act_caption[:act_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "            \n",
    "            actual_captions.append([' '.join(act_caption)])\n",
    "        texts=outputs\n",
    "        cands.extend([filter_cut_useless_words(text, filterd_words) for text in texts.tolist()])\n",
    "            # 参考文本\n",
    "        refs.extend([filter_cut_useless_words(cap, filterd_words) for cap in captions.tolist()])\n",
    "    \n",
    "    bleu4 = corpus_bleu(actual_captions, generated_captions, weights=(0.25,0.25,0.25,0.25))\n",
    "    \n",
    "    bleu4_token=get_BLEU_score(cands, refs)\n",
    "\n",
    "    cider_d_score=get_CIDER_D_score(test_dataset.vocab,refs, cands)\n",
    "    \n",
    "    spice_score=get_SPICE_score(test_dataset.vocab,refs, cands)\n",
    "    \n",
    "\n",
    "    print(f\"bleu4 :{bleu4}\")\n",
    "    print(f\"bleu4_token :{bleu4_token}\")\n",
    "    print(f\"cider_d_score :{cider_d_score}\")\n",
    "    print(f\"spice_score :{spice_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
