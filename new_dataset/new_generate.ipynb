{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTFeatureExtractor, BertTokenizer\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset='deepfashion-multimodal'\n",
    "img_path = f'data/{dataset}/test_image'\n",
    "vocab_path = f'data/{dataset}/vocab.json'\n",
    "\n",
    "def idx_to_word(idx, vocab):#将向量转化为文本描述\n",
    "    reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "    return reverse_vocab.get(int(idx), '<unk>')\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_folder, transform=None):\n",
    "        self.img_folder = img_folder\n",
    "        self.img_names = [img for img in os.listdir(img_folder) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(len(self.img_names))\n",
    "        print(self.img_names[0])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_folder, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.img_names[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, BertModel, BertConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Img2TxtModel(nn.Module):\n",
    "    def __init__(self, vit_model_name, transformer_config, vocab_size):\n",
    "        super(Img2TxtModel, self).__init__()\n",
    "        # ViT模型作为编码器\n",
    "        self.encoder = ViTModel.from_pretrained(vit_model_name)\n",
    "\n",
    "        # Transformer解码器配置\n",
    "        transformer_config = BertConfig(vocab_size=vocab_size, num_hidden_layers=1, is_decoder=True,  add_cross_attention=True)\n",
    "        self.decoder = BertModel(transformer_config)\n",
    "\n",
    "        # 预测每个词的线性层\n",
    "        self.vocab_size = vocab_size\n",
    "        self.fc = nn.Linear(transformer_config.hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids, decoder_input_ids, decoder_attention_mask):\n",
    "        # 通过ViT编码器获取图像特征\n",
    "        encoder_outputs = self.encoder(pixel_values=input_ids).last_hidden_state\n",
    "\n",
    "        # 将图像特征作为解码器的输入\n",
    "        decoder_outputs = self.decoder(input_ids=decoder_input_ids, \n",
    "                                       attention_mask=decoder_attention_mask,\n",
    "                                       encoder_hidden_states=encoder_outputs).last_hidden_state\n",
    "\n",
    "        # 预测下一个词\n",
    "        prediction_scores = self.fc(decoder_outputs)\n",
    "        return prediction_scores\n",
    "\n",
    "    def generate_text(self, input_ids, max_length=95, start_token_id=154):\n",
    "        # 获取图像特征\n",
    "        encoder_outputs = self.encoder(pixel_values=input_ids).last_hidden_state\n",
    "\n",
    "        # 初始化解码器输入为<start>标记\n",
    "        decoder_input_ids = torch.full((input_ids.size(0), 1), start_token_id).to(input_ids.device)\n",
    "        \n",
    "        # 存储所有时间步的logits\n",
    "        all_logits = []\n",
    "\n",
    "        for step in range(max_length):\n",
    "            # 获取解码器输出\n",
    "            decoder_outputs = self.decoder(\n",
    "                input_ids=decoder_input_ids, \n",
    "                encoder_hidden_states=encoder_outputs\n",
    "            ).last_hidden_state\n",
    "\n",
    "            # 预测下一个词\n",
    "            next_word_logits = self.fc(decoder_outputs[:, -1, :])\n",
    "            all_logits.append(next_word_logits.unsqueeze(1))\n",
    "            next_word_id = next_word_logits.argmax(dim=-1).unsqueeze(-1)\n",
    "            \n",
    "            # 将预测的词添加到解码器输入中\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, next_word_id], dim=-1)\n",
    "        \n",
    "        return decoder_input_ids ,torch.cat(all_logits, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "5\n",
      "MEN-Sweaters-id_00000702-06_7_additional.jpg\n",
      "{'MEN-Sweaters-id_00000702-06_7_additional.jpg': 'The person is wearing a short-sleeve shirt with graphic patterns. The shirt is with cotton fabric. It has a crew neckline. The person wears a three-point shorts. The shorts are with denim fabric and pure color patterns. There is an accessory on her wrist. There is a ring on her finger.', 'MEN-Sweatshirts_Hoodies-id_00000911-01_4_full.jpg': 'The person is wearing a tank tank top with graphic patterns. The tank top is with cotton fabric. It has a suspenders neckline. The person wears a long trousers. The trousers are with cotton fabric and graphic patterns. There is an accessory on her wrist. There is a ring on her finger.', 'WOMEN-Pants-id_00005000-06_1_front.jpg': 'The person is wearing a tank tank top with graphic patterns. The tank top is with cotton fabric. It has a suspenders neckline. The person wears a long trousers. The trousers are with cotton fabric and graphic patterns. There is an accessory on her wrist. There is a ring on her finger.', 'WOMEN-Rompers_Jumpsuits-id_00004968-01_2_side.jpg': 'The person is wearing a long-sleeve shirt with graphic patterns. The shirt is with cotton fabric and its neckline is round. The trousers the person wears is of long length. The trousers are with cotton fabric and solid color patterns. There is an accessory on his wrist.', 'WOMEN-Shorts-id_00006003-01_4_full.jpg': 'The tank top this person wears has no sleeves and it is with cotton fabric and graphic patterns. The neckline of the tank top is suspenders. This person wears a three-point pants, with denim fabric and solid color patterns. There is an accessory on her wrist. There is a ring on her finger.'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel, BertModel, BertConfig\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # 根据需要添加更多的转换\n",
    "])\n",
    "\n",
    "# 创建 Dataset 实例\n",
    "dataset = CustomImageDataset(img_folder=img_path, transform=transform)\n",
    "\n",
    "# 创建 DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "with open(vocab_path, 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "vit_model_name = 'google/vit-base-patch16-224-in21k'\n",
    "transformer_config = BertConfig()\n",
    "\n",
    "model = Img2TxtModel(vit_model_name, transformer_config, vocab_size)\n",
    "# 加载模型状态字典\n",
    "checkpoint = torch.load('./model/best_model_epoch_10_batch_2700.pth')\n",
    "\n",
    "\n",
    "# 将状态字典应用到模型实例中\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "\n",
    "generated_captions_dict = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, name in data_loader:\n",
    "        images = images.to(device)\n",
    "        input_ids = images\n",
    "        outputs,_ = model.generate_text(input_ids, max_length=95, start_token_id=vocab['<start>'])\n",
    "        for i in range(outputs.shape[0]):\n",
    "            gen_caption = [idx_to_word(idx, vocab) for idx in outputs[i]]\n",
    "            if '<start>' in gen_caption:\n",
    "                gen_caption = gen_caption[1:]  # 移除第一个元素 (<start>)\n",
    "            if '<end>' in gen_caption:\n",
    "                gen_caption = gen_caption[:gen_caption.index('<end>')]  # 移除 <end> 及其后面的元素\n",
    "\n",
    "            caption_text = ' '.join(gen_caption)\n",
    "            generated_captions_dict[name[0]] = caption_text\n",
    "    print(generated_captions_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
